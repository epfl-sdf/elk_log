input {
  file {
    path => "/home/ubuntu/data-elk/wwp_all_clean.log"
    start_position => "beginning"
    sincedb_path => "/dev/null"
  }
}

filter { 
 csv {
   separator => " - "
   columns => [
               "zdate",
               "xroot",
               "xerror",
               "site",
               "zoperation",
               "zerror"
               ] 
   quote_char => "$"
   }

 mutate {
#   gsub => [
#       "site", " ", "_",
#       "zstatus", " ", "_",
#       "zerror", " ", "_",
#       "zerror", "-", "_"
#           ]
   remove_field => ["xroot", "xerror"]
   convert => {
              "site" => "string"
              "zoperation" => "string"
              "zerror" => "string"            
              }
        }

 if ![zoperation]{
   ruby{
      code => "event.set('nom_erreur' , event.get('site') ); event.set('site' , 'no_parent');"
       }
              }
 else {
   ruby{
      code => "seperation1 = event.get('zerror').split(/: /);
               event.set('code_erreur',  seperation1[0]);
               event.set('nom_erreur' , seperation1[1]); "
       }
      }
 date {
   match => ["zdate", "yyyy-MM-dd HH:mm:ss,SSS"]
#   add_field => {"code_erreur_unanalyzed" => "%{code_erreur_analyzed}"}
#   add_field => {"nom_erreur_unanalyzed" => "%{nom_erreur_analyzed}"}
      }
}

output {
  elasticsearch
        {
    hosts => ["${ELASTOC_SRV}"]
    index => ["${ELASTOC_IDX}"]
    document_type => "logstash_csv"
        }
  stdout{
    codec => json
        }
}
